{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mountain Car Example\n",
    "\n",
    "Let's see how to make this API work with Mountain Car! This reinforcement learning API requires 3 things to be defined before we start running algorithms:\n",
    "\n",
    "+ BlackBoxModel: defines the problem--see below for an example!\n",
    "+ Policy: this is where your domain knowledge comes in--define action space and feature functions\n",
    "+ Solver: This is where the API takes over and you just specify what you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include(joinpath(\"..\",\"src\",\"ReinforcementLearning.jl\"))\n",
    "using ReinforcementLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Black Box Model Functions\n",
    "\n",
    "The BlackBoxModel type requires the following things to be defined:\n",
    "+ `model`: a generic type that holds all your model parameters for a specific instance of your problem\n",
    "+ `init(model,rng)`: generate an initial state\n",
    "+ `observe(model,rng,state,action=None)`: return an observation based on your state (and action--this isn't quite ironed out yet)\n",
    "+ `next_state(model,rng,state,action)`: generate a next state given your state, action and problem parameterization\n",
    "+ `reward(model,rng,state,action)`: generate a reward based on your state and action and problem parameterization\n",
    "+ `isterminal(model,state,action)`: return a boolean of whether a state (and action) is terminal or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type MtnCarModel <: Model\n",
    "    cost::Float64\n",
    "end\n",
    "MtnCarModel() = MtnCarModel(-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init2(m::MtnCarModel,rng::AbstractRNG) = [1.8*rand()-1.2;0.14*rand()-0.07]\n",
    "init1(m::MtnCarModel,rng::AbstractRNG) = [-0.5;0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function next_state(rng::AbstractRNG,model::MtnCarModel,s::Array{Float64,1},a::Float64)\n",
    "    x,v = s\n",
    "    v_ = v + a*0.001+cos(3*x)*-0.0025\n",
    "    v_ = max(min(0.07,v_),-0.07)\n",
    "    x_ = x+v_\n",
    "    #inelastic boundary\n",
    "    if x_ < -1.2\n",
    "        x_ = -1.2\n",
    "        v_ = 0.\n",
    "    end\n",
    "    return [x_;v_]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isterminal(rng::AbstractRNG,m::MtnCarModel,s::Array{Float64,1},a::Float64) = s[1] >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward(rng::AbstractRNG,m::MtnCarModel,s::Array{Float64,1},a::Float64) = isterminal(rng,m,s,a) ? 0.: m.cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the BlackBoxModel type. Note that we do not include an observation function in the constructor--in this case, it uses a default identity observation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbm = BlackBoxModel(MtnCarModel(),init1,next_state,reward,isterminal) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Policy\n",
    "\n",
    "In general for a policy, we have to define an ActionSpace (which we require to be exactly or a subset of the true action space), and feature function, which maps the state into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = DiscreteActionSpace([-1.;0.;1.]) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tile coding is provided (the API for tilecoding needs work, however) for a quick and dirty function approximator in the continuous domain. For concreteness/generality, we include a function `cast_mc_state`, which in the most general case, will convert whatever state representation you have into an array of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for concreteness, this function converts statespace to an array\n",
    "cast_mc_state(x)=x\n",
    "__feature_function_ = generate_tilecoder(10,10,A,[-1.2;-0.07],[0.6;0.07])\n",
    "feature_function(s,a)=__feature_function_(cast_mc_state(s),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy = EpsilonGreedyPolicy(feature_function,A,rng=MersenneTwister(3234),eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose and Set up your Solver\n",
    "\n",
    "Currently, the following solvers are supported:\n",
    "+ Forgetful LSTD(\\lambda) / LS-SARSA (untested)\n",
    "+ SARSA(\\lamda) (untested)\n",
    "+ Q(\\lambda) (unimplemented)\n",
    "+ GQ(\\lambda) (unimplemented)\n",
    "+ Double Q learning (untested)\n",
    "+ Deterministic Policy Gradient (unimplemented)\n",
    "+ (Natural) Actor-Critic (unimplemented\n",
    "\n",
    "We just ask that you know a-priori how big your feature vectors are to make initialization easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#there might be a smart way to stick this into a constructor, but for now...\n",
    "nb_features = length(policy.feature_function(bbm.state,domain(A)[1]))\n",
    "#updater = ForgetfulLSTDParam(nb_features,alpha=0.001/3)\n",
    "#updater = SARSAParam(nb_features,lambda=0.7,init_method=\"zero\",trace_type=\"replacing\")\n",
    "updater = TrueOnlineTDParam(nb_features,lambda=0.95,init_method=\"unif_rand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually set up the real solver\n",
    "\n",
    "Some random cool things supported include:\n",
    "+ minibatching\n",
    "+ experience replay\n",
    "+ adaptive learning rates, e.g.:\n",
    "    * momentum\n",
    "    * nesterov momentum\n",
    "    * rmsprop\n",
    "    * adagrad\n",
    "    * adadelta\n",
    "    * adam\n",
    "+ simulated annealing (probably shouldn't support this)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver = Solver(updater,\n",
    "                lr=0.1,\n",
    "                nb_episodes=50,\n",
    "                nb_timesteps=5000,\n",
    "                discount=0.99,\n",
    "                annealer=NullAnnealer(),\n",
    "                mb=NullMinibatcher(),\n",
    "                er=NullExperienceReplayer(),\n",
    "                display_interval=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trained_policy = solve(solver,bbm,policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Policy\n",
    "Basically just run a couple of simulations -- the simulator api is a subset of the stuff you see in solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim = Simulator(discount=1.,nb_sim=25,nb_timesteps=6000) #stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns average reward for now...\n",
    "bbm.init = init1\n",
    "R_avg = simulate(sim,bbm,trained_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = zeros(sim.nb_timesteps)\n",
    "V = zeros(sim.nb_timesteps)\n",
    "A = zeros(sim.nb_timesteps)\n",
    "R_tot = 0.\n",
    "s = init(bbm)\n",
    "a = action(trained_policy,s) #TODO: stuff\n",
    "for t = 0:(sim.nb_timesteps-1)\n",
    "    r, s_ = next(bbm,a)\n",
    "    a_ = action(trained_policy,s_)\n",
    "    X[t+1] = s_[1]\n",
    "    V[t+1] = s_[2]\n",
    "    A[t+1] = a_\n",
    "    gamma = isterminal(bbm,a_) ? 0. : sim.discount^t\n",
    "    R_tot += gamma*r\n",
    "    if gamma == 0.\n",
    "      break\n",
    "    end\n",
    "    #push the update frame up one time step as it were\n",
    "    s = s_\n",
    "    a = a_\n",
    "end\n",
    "\n",
    "subplot(311)\n",
    "plot(X)\n",
    "subplot(312)\n",
    "plot(V)\n",
    "subplot(313)\n",
    "plot(A)\n",
    "\n",
    "println(R_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Iterators.product\n",
    "nb_pts = 5\n",
    "xs = linspace(-1.2,0.6,nb_pts)\n",
    "vs = linspace(-0.07,0.07,nb_pts)\n",
    "ss = product(xs,vs)\n",
    "As = [xv=>action(trained_policy,[xv[1];xv[2]]) for xv in ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[dot(weights(updater),feature_function(bbm.state,a)) for a in domain(A)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action(trained_policy,bbm.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_policy.weights == weights(updater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi = feature_function(bbm.state,0.)\n",
    "zeros(3000) + vec(updater.beta*phi*dot(updater.e,phi) + phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeros(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(updater.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "10*0.99*0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi = policy.feature_function(bbm.state,domain(A)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(max(zeros(3000),phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updater.lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm((rand(3000)-0.5)/sqrt(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm(rand(3000)-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_feat = length(policy.feature_function(bbm.state,0.))\n",
    "Rs = zeros(100)\n",
    "for ep in 1:100\n",
    "    R = 0.\n",
    "    updater.e = zeros(nb_feat)\n",
    "    s = init(bbm)\n",
    "    a = action(policy,updater,s)\n",
    "    phi = policy.feature_function(s,a)\n",
    "    for t = 1:5000\n",
    "        r,s_ = next(bbm,a)\n",
    "        a_ = action(policy,updater,s_)\n",
    "        R += r\n",
    "        \n",
    "        phi_ = feature_function(s_,a_)\n",
    "        gamma = isterminal(bbm,a_) ? 0. : 0.99\n",
    "        q = dot(updater.w,phi)\n",
    "        q_ = dot(updater.w,phi_)\n",
    "        del = r + gamma*q_ - q\n",
    "        updater.e = vec(max(phi,updater.e))\n",
    "        dw = 0.01*updater.e*del\n",
    "        updater.w  = vec(updater.w + dw)\n",
    "        updater.e = vec(updater.e*0.95*gamma)\n",
    "        \n",
    "        if isterminal(bbm,a_)\n",
    "            break\n",
    "        end\n",
    "        phi = phi_\n",
    "    end\n",
    "    Rs[ep] = R\n",
    "end\n",
    "plot(Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_policy = Policy(policy,updater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "R = 0.\n",
    "for ep in 1:100\n",
    "    s = init(bbm)\n",
    "    a = action(trained_policy,s)\n",
    "    for t = 1:5000\n",
    "        r,s_ = next(bbm,a)\n",
    "        a_ = action(trained_policy,s_)\n",
    "        R += r\n",
    "        if isterminal(bbm,a_)\n",
    "            break\n",
    "        end\n",
    "        a = a_\n",
    "    end\n",
    "end\n",
    "\n",
    "R/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.2",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
